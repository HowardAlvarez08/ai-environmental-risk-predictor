{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HowardAlvarez08/ai-environmental-risk-predictor/blob/main/AI_Prediction_(Plan_B).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Season 1: Historical Dataset ML Training"
      ],
      "metadata": {
        "id": "oj0jbPZTwIaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 1 â€” Setup & Install Dependencies (RUN THIS FIRST)"
      ],
      "metadata": {
        "id": "BfTifDs9rRk6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w88N8WHeHzVs",
        "outputId": "ad7943cf-17ab-403a-b8f6-5e7d7c6a794e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openmeteo-requests\n",
            "  Downloading openmeteo_requests-1.7.5-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting requests-cache\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting retry-requests\n",
            "  Downloading retry_requests-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting niquests>=3.15.2 (from openmeteo-requests)\n",
            "  Downloading niquests-3.17.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting openmeteo-sdk>=1.22.0 (from openmeteo-requests)\n",
            "  Downloading openmeteo_sdk-1.25.0-py3-none-any.whl.metadata (935 bytes)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (25.4.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache)\n",
            "  Downloading cattrs-25.3.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (2.32.4)\n",
            "Collecting url-normalize>=1.4 (from requests-cache)\n",
            "  Downloading url_normalize-2.2.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from cattrs>=22.2->requests-cache) (4.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from niquests>=3.15.2->openmeteo-requests) (3.4.4)\n",
            "Collecting urllib3-future<3,>=2.13.903 (from niquests>=3.15.2->openmeteo-requests)\n",
            "  Downloading urllib3_future-2.15.901-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting wassima<3,>=1.0.1 (from niquests>=3.15.2->openmeteo-requests)\n",
            "  Downloading wassima-2.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting flatbuffers==25.9.23 (from openmeteo-sdk>=1.22.0->openmeteo-requests)\n",
            "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->requests-cache) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->requests-cache) (2026.1.4)\n",
            "Requirement already satisfied: h11<1.0.0,>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests) (0.16.0)\n",
            "Collecting jh2<6.0.0,>=5.0.3 (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests)\n",
            "  Downloading jh2-5.0.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting qh3<2.0.0,>=1.5.4 (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests)\n",
            "  Downloading qh3-1.5.6-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Downloading openmeteo_requests-1.7.5-py3-none-any.whl (7.1 kB)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retry_requests-2.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading cattrs-25.3.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading niquests-3.17.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmeteo_sdk-1.25.0-py3-none-any.whl (19 kB)\n",
            "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
            "Downloading url_normalize-2.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading urllib3_future-2.15.901-py3-none-any.whl (684 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m684.7/684.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wassima-2.0.4-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jh2-5.0.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (394 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m394.1/394.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qh3-1.5.6-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flatbuffers, wassima, url-normalize, qh3, openmeteo-sdk, jh2, cattrs, urllib3-future, retry-requests, requests-cache, niquests, openmeteo-requests\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.12.19\n",
            "    Uninstalling flatbuffers-25.12.19:\n",
            "      Successfully uninstalled flatbuffers-25.12.19\n",
            "Successfully installed cattrs-25.3.0 flatbuffers-25.9.23 jh2-5.0.10 niquests-3.17.0 openmeteo-requests-1.7.5 openmeteo-sdk-1.25.0 qh3-1.5.6 requests-cache-1.2.1 retry-requests-2.0.0 url-normalize-2.2.1 urllib3-future-2.15.901 wassima-2.0.4\n"
          ]
        }
      ],
      "source": [
        "# STEP 1 â€” Setup & Install Dependencies (RUN THIS FIRST)\n",
        "\n",
        "!pip install openmeteo-requests requests-cache retry-requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For compatibility\n",
        "\n",
        "!pip install -q urllib3==1.26.18 requests-cache retry-requests openmeteo-requests"
      ],
      "metadata": {
        "id": "C49dFV--qzhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fb3481-ee5a-4644-9651-ebf816f3c1a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŸ© STEP 2 â€” Import Libraries (Cell 2)"
      ],
      "metadata": {
        "id": "lZxr1gU3rVeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import openmeteo_requests\n",
        "import requests_cache\n",
        "from retry_requests import retry\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "iCMkrGECH55s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŸ© STEP 3 â€” Fetch HISTORICAL DAILY DATA (Cell 3)"
      ],
      "metadata": {
        "id": "QfhskiUdrh_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ðŸŸ© STEP 3 â€” Fetch HISTORICAL DAILY DATA (Cell 3)\n",
        "\n",
        "# Setup the Open-Meteo API client with cache and retry on error\n",
        "cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
        "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
        "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
        "\n",
        "# Make sure all required weather variables are listed here\n",
        "# The order of variables in hourly or daily is important to assign them correctly below\n",
        "url = \"https://historical-forecast-api.open-meteo.com/v1/forecast\"\n",
        "params = {\n",
        "\t\"latitude\": 14.5995,\n",
        "\t\"longitude\": 120.9842,\n",
        "\t\"start_date\": \"2018-01-01\",\n",
        "\t\"end_date\": \"2023-12-31\",\n",
        "\t\"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"precipitation\", \"rain\", \"soil_moisture_0_to_1cm\", \"soil_moisture_1_to_3cm\", \"soil_moisture_3_to_9cm\", \"soil_moisture_9_to_27cm\", \"soil_moisture_27_to_81cm\", \"soil_temperature_0cm\", \"soil_temperature_6cm\", \"soil_temperature_18cm\", \"soil_temperature_54cm\", \"wind_speed_10m\", \"wind_direction_10m\", \"wind_gusts_10m\", \"pressure_msl\", \"cloud_cover\", \"visibility\", \"cape\", \"lifted_index\", \"convective_inhibition\"],\n",
        "\t\"timezone\": \"Asia/Singapore\",\n",
        "}\n",
        "responses = openmeteo.weather_api(url, params=params)\n",
        "\n",
        "# Process first location. Add a for-loop for multiple locations or weather models\n",
        "response = responses[0]\n",
        "print(f\"Coordinates: {response.Latitude()}Â°N {response.Longitude()}Â°E\")\n",
        "print(f\"Elevation: {response.Elevation()} m asl\")\n",
        "print(f\"Timezone: {response.Timezone()}{response.TimezoneAbbreviation()}\")\n",
        "print(f\"Timezone difference to GMT+0: {response.UtcOffsetSeconds()}s\")\n",
        "\n",
        "# Process hourly data. The order of variables needs to be the same as requested.\n",
        "hourly = response.Hourly()\n",
        "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
        "hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
        "hourly_dew_point_2m = hourly.Variables(2).ValuesAsNumpy()\n",
        "hourly_precipitation = hourly.Variables(3).ValuesAsNumpy()\n",
        "hourly_rain = hourly.Variables(4).ValuesAsNumpy()\n",
        "hourly_soil_moisture_0_to_1cm = hourly.Variables(5).ValuesAsNumpy()\n",
        "hourly_soil_moisture_1_to_3cm = hourly.Variables(6).ValuesAsNumpy()\n",
        "hourly_soil_moisture_3_to_9cm = hourly.Variables(7).ValuesAsNumpy()\n",
        "hourly_soil_moisture_9_to_27cm = hourly.Variables(8).ValuesAsNumpy()\n",
        "hourly_soil_moisture_27_to_81cm = hourly.Variables(9).ValuesAsNumpy()\n",
        "hourly_soil_temperature_0cm = hourly.Variables(10).ValuesAsNumpy()\n",
        "hourly_soil_temperature_6cm = hourly.Variables(11).ValuesAsNumpy()\n",
        "hourly_soil_temperature_18cm = hourly.Variables(12).ValuesAsNumpy()\n",
        "hourly_soil_temperature_54cm = hourly.Variables(13).ValuesAsNumpy()\n",
        "hourly_wind_speed_10m = hourly.Variables(14).ValuesAsNumpy()\n",
        "hourly_wind_direction_10m = hourly.Variables(15).ValuesAsNumpy()\n",
        "hourly_wind_gusts_10m = hourly.Variables(16).ValuesAsNumpy()\n",
        "hourly_pressure_msl = hourly.Variables(17).ValuesAsNumpy()\n",
        "hourly_cloud_cover = hourly.Variables(18).ValuesAsNumpy()\n",
        "hourly_visibility = hourly.Variables(19).ValuesAsNumpy()\n",
        "hourly_cape = hourly.Variables(20).ValuesAsNumpy()\n",
        "hourly_lifted_index = hourly.Variables(21).ValuesAsNumpy()\n",
        "hourly_convective_inhibition = hourly.Variables(22).ValuesAsNumpy()\n",
        "\n",
        "hourly_data = {\"date\": pd.date_range(\n",
        "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
        "\tend =  pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
        "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
        "\tinclusive = \"left\"\n",
        ")}\n",
        "\n",
        "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
        "hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
        "hourly_data[\"dew_point_2m\"] = hourly_dew_point_2m\n",
        "hourly_data[\"precipitation\"] = hourly_precipitation\n",
        "hourly_data[\"rain\"] = hourly_rain\n",
        "hourly_data[\"soil_moisture_0_to_1cm\"] = hourly_soil_moisture_0_to_1cm\n",
        "hourly_data[\"soil_moisture_1_to_3cm\"] = hourly_soil_moisture_1_to_3cm\n",
        "hourly_data[\"soil_moisture_3_to_9cm\"] = hourly_soil_moisture_3_to_9cm\n",
        "hourly_data[\"soil_moisture_9_to_27cm\"] = hourly_soil_moisture_9_to_27cm\n",
        "hourly_data[\"soil_moisture_27_to_81cm\"] = hourly_soil_moisture_27_to_81cm\n",
        "hourly_data[\"soil_temperature_0cm\"] = hourly_soil_temperature_0cm\n",
        "hourly_data[\"soil_temperature_6cm\"] = hourly_soil_temperature_6cm\n",
        "hourly_data[\"soil_temperature_18cm\"] = hourly_soil_temperature_18cm\n",
        "hourly_data[\"soil_temperature_54cm\"] = hourly_soil_temperature_54cm\n",
        "hourly_data[\"wind_speed_10m\"] = hourly_wind_speed_10m\n",
        "hourly_data[\"wind_direction_10m\"] = hourly_wind_direction_10m\n",
        "hourly_data[\"wind_gusts_10m\"] = hourly_wind_gusts_10m\n",
        "hourly_data[\"pressure_msl\"] = hourly_pressure_msl\n",
        "hourly_data[\"cloud_cover\"] = hourly_cloud_cover\n",
        "hourly_data[\"visibility\"] = hourly_visibility\n",
        "hourly_data[\"cape\"] = hourly_cape\n",
        "hourly_data[\"lifted_index\"] = hourly_lifted_index\n",
        "hourly_data[\"convective_inhibition\"] = hourly_convective_inhibition\n",
        "\n",
        "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
        "hourly_dataframe[\"date\"] = (\n",
        "    hourly_dataframe[\"date\"]\n",
        "    .dt.tz_convert(\"Asia/Manila\")  # UTC â†’ PH time\n",
        "    .dt.tz_localize(None)          # remove timezone info\n",
        ")\n",
        "\n",
        "print(\"\\nHourly data\\n\", hourly_dataframe)"
      ],
      "metadata": {
        "id": "7HdtFt8YI1tG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "outputId": "7cd881ae-b0a8-414e-9b5a-d045619521b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenMeteoRequestsError",
          "evalue": "failed to request 'https://historical-forecast-api.open-meteo.com/v1/forecast': HTTPSConnectionPool(host='historical-forecast-api.open-meteo.com', port=443): Max retries exceeded with url: /v1/forecast?latitude=14.5995&longitude=120.9842&start_date=2018-01-01&end_date=2023-12-31&hourly=temperature_2m&hourly=relative_humidity_2m&hourly=dew_point_2m&hourly=precipitation&hourly=rain&hourly=soil_moisture_0_to_1cm&hourly=soil_moisture_1_to_3cm&hourly=soil_moisture_3_to_9cm&hourly=soil_moisture_9_to_27cm&hourly=soil_moisture_27_to_81cm&hourly=soil_temperature_0cm&hourly=soil_temperature_6cm&hourly=soil_temperature_18cm&hourly=soil_temperature_54cm&hourly=wind_speed_10m&hourly=wind_direction_10m&hourly=wind_gusts_10m&hourly=pressure_msl&hourly=cloud_cover&hourly=visibility&hourly=cape&hourly=lifted_index&hourly=convective_inhibition&timezone=Asia%2FSingapore&format=flatbuffers (Caused by ResponseError('too many 500 error responses'))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    895\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    895\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    895\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    895\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    895\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mretries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='historical-forecast-api.open-meteo.com', port=443): Max retries exceeded with url: /v1/forecast?latitude=14.5995&longitude=120.9842&start_date=2018-01-01&end_date=2023-12-31&hourly=temperature_2m&hourly=relative_humidity_2m&hourly=dew_point_2m&hourly=precipitation&hourly=rain&hourly=soil_moisture_0_to_1cm&hourly=soil_moisture_1_to_3cm&hourly=soil_moisture_3_to_9cm&hourly=soil_moisture_9_to_27cm&hourly=soil_moisture_27_to_81cm&hourly=soil_temperature_0cm&hourly=soil_temperature_6cm&hourly=soil_temperature_18cm&hourly=soil_temperature_54cm&hourly=wind_speed_10m&hourly=wind_direction_10m&hourly=wind_gusts_10m&hourly=pressure_msl&hourly=cloud_cover&hourly=visibility&hourly=cape&hourly=lifted_index&hourly=convective_inhibition&timezone=Asia%2FSingapore&format=flatbuffers (Caused by ResponseError('too many 500 error responses'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openmeteo_requests/Client.py\u001b[0m in \u001b[0;36mweather_api\u001b[0;34m(self, url, params, method, verify, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             return self._request(\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openmeteo_requests/Client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, url, method, params, verify, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests_cache/session.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, params, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests_cache/session.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, headers, expire_after, only_if_cached, refresh, force_refresh, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpatch_form_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests_cache/session.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, expire_after, only_if_cached, refresh, force_refresh, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_request\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_and_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests_cache/session.py\u001b[0m in \u001b[0;36m_send_and_cache\u001b[0;34m(self, request, actions, cached_response, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRetryError\u001b[0m: HTTPSConnectionPool(host='historical-forecast-api.open-meteo.com', port=443): Max retries exceeded with url: /v1/forecast?latitude=14.5995&longitude=120.9842&start_date=2018-01-01&end_date=2023-12-31&hourly=temperature_2m&hourly=relative_humidity_2m&hourly=dew_point_2m&hourly=precipitation&hourly=rain&hourly=soil_moisture_0_to_1cm&hourly=soil_moisture_1_to_3cm&hourly=soil_moisture_3_to_9cm&hourly=soil_moisture_9_to_27cm&hourly=soil_moisture_27_to_81cm&hourly=soil_temperature_0cm&hourly=soil_temperature_6cm&hourly=soil_temperature_18cm&hourly=soil_temperature_54cm&hourly=wind_speed_10m&hourly=wind_direction_10m&hourly=wind_gusts_10m&hourly=pressure_msl&hourly=cloud_cover&hourly=visibility&hourly=cape&hourly=lifted_index&hourly=convective_inhibition&timezone=Asia%2FSingapore&format=flatbuffers (Caused by ResponseError('too many 500 error responses'))",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOpenMeteoRequestsError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-507883483.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;34m\"timezone\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Asia/Singapore\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenmeteo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweather_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Process first location. Add a for-loop for multiple locations or weather models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openmeteo_requests/Client.py\u001b[0m in \u001b[0;36mweather_api\u001b[0;34m(self, url, params, method, verify, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"failed to request {url!r}: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOpenMeteoRequestsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenMeteoRequestsError\u001b[0m: failed to request 'https://historical-forecast-api.open-meteo.com/v1/forecast': HTTPSConnectionPool(host='historical-forecast-api.open-meteo.com', port=443): Max retries exceeded with url: /v1/forecast?latitude=14.5995&longitude=120.9842&start_date=2018-01-01&end_date=2023-12-31&hourly=temperature_2m&hourly=relative_humidity_2m&hourly=dew_point_2m&hourly=precipitation&hourly=rain&hourly=soil_moisture_0_to_1cm&hourly=soil_moisture_1_to_3cm&hourly=soil_moisture_3_to_9cm&hourly=soil_moisture_9_to_27cm&hourly=soil_moisture_27_to_81cm&hourly=soil_temperature_0cm&hourly=soil_temperature_6cm&hourly=soil_temperature_18cm&hourly=soil_temperature_54cm&hourly=wind_speed_10m&hourly=wind_direction_10m&hourly=wind_gusts_10m&hourly=pressure_msl&hourly=cloud_cover&hourly=visibility&hourly=cape&hourly=lifted_index&hourly=convective_inhibition&timezone=Asia%2FSingapore&format=flatbuffers (Caused by ResponseError('too many 500 error responses'))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 4 â€” Convert to Pandas DataFrame (Cell 4)"
      ],
      "metadata": {
        "id": "gpnbbJvUrmt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 4 â€” Prepare Hourly DataFrame\n",
        "# ===============================\n",
        "\n",
        "# Copy hourly data to working DF\n",
        "df = hourly_dataframe.copy()\n",
        "\n",
        "# Rename columns to match feature engineering / ML pipeline naming\n",
        "df.rename(columns={\n",
        "    \"temperature_2m\": \"temperature_mean\",\n",
        "    \"relative_humidity_2m\": \"relative_humidity_mean\",\n",
        "    \"pressure_msl\": \"sea_level_pressure_mean\",\n",
        "    \"soil_moisture_27_to_81cm\": \"soil_moisture_mean\",\n",
        "    \"wind_speed_10m\": \"wind_speed_max\",\n",
        "    \"wind_gusts_10m\": \"wind_gust_max\",\n",
        "    \"precipitation\": \"precipitation_sum\",\n",
        "    \"rain\": \"rain_sum\",\n",
        "    \"cloud_cover\": \"cloud_cover_total\",\n",
        "    \"dew_point_2m\": \"dew_point_mean\",\n",
        "    \"soil_moisture_0_to_1cm\": \"soil_moisture_top\",\n",
        "    \"soil_moisture_1_to_3cm\": \"soil_moisture_1_3cm\",\n",
        "    \"soil_moisture_3_to_9cm\": \"soil_moisture_3_9cm\",\n",
        "    \"soil_moisture_9_to_27cm\": \"soil_moisture_9_27cm\",\n",
        "    \"soil_temperature_0cm\": \"soil_temperature_top\",\n",
        "    \"soil_temperature_6cm\": \"soil_temperature_6cm\",\n",
        "    \"soil_temperature_18cm\": \"soil_temperature_18cm\",\n",
        "    \"soil_temperature_54cm\": \"soil_temperature_54cm\"\n",
        "}, inplace=True)\n",
        "\n",
        "# Optional: keep only the relevant columns for ML\n",
        "df = df[[\n",
        "    \"temperature_mean\",\n",
        "    \"relative_humidity_mean\",\n",
        "    \"dew_point_mean\",\n",
        "    \"precipitation_sum\",\n",
        "    \"rain_sum\",\n",
        "    \"soil_moisture_mean\",\n",
        "    \"soil_moisture_top\",\n",
        "    \"soil_moisture_1_3cm\",\n",
        "    \"soil_moisture_3_9cm\",\n",
        "    \"soil_moisture_9_27cm\",\n",
        "    \"soil_temperature_top\",\n",
        "    \"soil_temperature_6cm\",\n",
        "    \"soil_temperature_18cm\",\n",
        "    \"soil_temperature_54cm\",\n",
        "    \"wind_speed_max\",\n",
        "    \"wind_gust_max\",\n",
        "    \"sea_level_pressure_mean\",\n",
        "    \"cloud_cover_total\",\n",
        "    \"visibility\",\n",
        "    \"cape\",\n",
        "    \"lifted_index\",\n",
        "    \"convective_inhibition\"\n",
        "]]\n",
        "\n",
        "# Quick check\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "JkKFSKxoJNAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Value Heatmap\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='coolwarm')\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oHEbqoPfrySF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count total nulls\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GC4d8-76spsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4.5: Fix timezone and handle NaNs"
      ],
      "metadata": {
        "id": "KgZsAiwh6KLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 4.5 â€” Fix Timezone & Handle NaNs\n",
        "# ===============================\n",
        "\n",
        "# Copy dataframe\n",
        "df = hourly_dataframe.copy()\n",
        "\n",
        "# 1ï¸âƒ£ Fix timezone (UTC â†’ PH Time)\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True).dt.tz_convert(\"Asia/Manila\").dt.tz_localize(None)\n",
        "\n",
        "# 2ï¸âƒ£ Handle NaN values\n",
        "\n",
        "# Fill precipitation and rain NaNs with 0\n",
        "for col in [\"precipitation\", \"rain\", \"precipitation_sum\", \"rain_sum\"]:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "# Continuous variables to interpolate\n",
        "continuous_cols = [\n",
        "    \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\",\n",
        "    \"pressure_msl\", \"wind_speed_10m\", \"wind_gusts_10m\",\n",
        "    \"soil_moisture_0_to_1cm\", \"soil_moisture_1_to_3cm\", \"soil_moisture_3_to_9cm\",\n",
        "    \"soil_moisture_9_to_27cm\", \"soil_moisture_27_to_81cm\",\n",
        "    \"soil_temperature_0cm\", \"soil_temperature_6cm\", \"soil_temperature_18cm\", \"soil_temperature_54cm\",\n",
        "    \"cape\", \"lifted_index\", \"convective_inhibition\",\n",
        "    \"cloud_cover\", \"visibility\"\n",
        "]\n",
        "\n",
        "# Only keep columns that exist in df\n",
        "continuous_cols = [col for col in continuous_cols if col in df.columns]\n",
        "\n",
        "# Linear interpolation for continuous variables\n",
        "df[continuous_cols] = df[continuous_cols].interpolate(method=\"linear\")\n",
        "\n",
        "# Forward/backward fill any remaining NaNs\n",
        "df = df.ffill().bfill()\n",
        "\n",
        "# 3ï¸âƒ£ Rename columns to match model\n",
        "df.rename(columns={\n",
        "    \"temperature_2m\": \"temperature_mean\",\n",
        "    \"rain\": \"rain_sum\",\n",
        "    \"precipitation\": \"precipitation_sum\",\n",
        "    \"relative_humidity_2m\": \"relative_humidity_mean\",\n",
        "    \"pressure_msl\": \"sea_level_pressure_mean\",\n",
        "    \"soil_moisture_27_to_81cm\": \"soil_moisture_mean\",\n",
        "    \"wind_speed_10m\": \"wind_speed_max\",\n",
        "    \"wind_gusts_10m\": \"wind_gust_max\",\n",
        "    \"dew_point_2m\": \"dew_point_mean\",\n",
        "    \"cloud_cover\": \"cloud_cover_total\",\n",
        "    \"soil_moisture_0_to_1cm\": \"soil_moisture_top\",\n",
        "    \"soil_moisture_1_to_3cm\": \"soil_moisture_1_3cm\",\n",
        "    \"soil_moisture_3_to_9cm\": \"soil_moisture_3_9cm\",\n",
        "    \"soil_moisture_9_to_27cm\": \"soil_moisture_9_27cm\",\n",
        "    \"soil_temperature_0cm\": \"soil_temperature_top\",\n",
        "    \"soil_temperature_6cm\": \"soil_temperature_6cm\",\n",
        "    \"soil_temperature_18cm\": \"soil_temperature_18cm\",\n",
        "    \"soil_temperature_54cm\": \"soil_temperature_54cm\"\n",
        "}, inplace=True)\n",
        "\n",
        "# 4ï¸âƒ£ Quick NaN check\n",
        "print(\"NaN values after handling:\\n\", df.isnull().sum())\n",
        "\n",
        "# 5ï¸âƒ£ Preview\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "jaUeGkFB6KyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: FEATURE ENGINEERING"
      ],
      "metadata": {
        "id": "cTBbiF_0lMMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 5 â€” FEATURE ENGINEERING (Hourly)\n",
        "# ===============================\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure datetime and set index\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.set_index('date').sort_index()\n",
        "\n",
        "# -------------------------------\n",
        "# LAG FEATURES (hourly)\n",
        "# -------------------------------\n",
        "lag_hours = [1, 6, 24]\n",
        "\n",
        "# Rain/Precipitation lags\n",
        "for lag in lag_hours:\n",
        "    df[f'rain_lag{lag}h'] = df['rain_sum'].shift(lag)\n",
        "    df[f'precip_lag{lag}h'] = df['precipitation_sum'].shift(lag)\n",
        "\n",
        "# Soil moisture lags\n",
        "for lag in lag_hours:\n",
        "    df[f'soil_lag{lag}h'] = df['soil_moisture_mean'].shift(lag)\n",
        "\n",
        "# Wind gust lags (for storm/wind prediction)\n",
        "for lag in lag_hours:\n",
        "    df[f'wind_gust_lag{lag}h'] = df['wind_gust_max'].shift(lag)\n",
        "\n",
        "# -------------------------------\n",
        "# ROLLING SUMS / MEANS\n",
        "# -------------------------------\n",
        "# Rainfall accumulation\n",
        "df['rain_6h_sum'] = df['rain_sum'].rolling(6).sum()\n",
        "df['rain_12h_sum'] = df['rain_sum'].rolling(12).sum()\n",
        "df['rain_24h_sum'] = df['rain_sum'].rolling(24).sum()\n",
        "df['rain_24h_mean'] = df['rain_sum'].rolling(24).mean()\n",
        "\n",
        "# Wind gust rolling max\n",
        "df['wind_gust_6h_max'] = df['wind_gust_max'].rolling(6).max()\n",
        "df['wind_gust_12h_max'] = df['wind_gust_max'].rolling(12).max()\n",
        "df['wind_gust_24h_max'] = df['wind_gust_max'].rolling(24).max()\n",
        "\n",
        "# Soil moisture rolling mean\n",
        "df['soil_6h_mean'] = df['soil_moisture_mean'].rolling(6).mean()\n",
        "df['soil_12h_mean'] = df['soil_moisture_mean'].rolling(12).mean()\n",
        "df['soil_24h_mean'] = df['soil_moisture_mean'].rolling(24).mean()\n",
        "\n",
        "# -------------------------------\n",
        "# EXTREME EVENT INDICATORS\n",
        "# -------------------------------\n",
        "# Heavy rainfall\n",
        "df['heavy_rain'] = (df['rain_sum'] >= 50).astype(int)\n",
        "df['very_heavy_rain'] = (df['rain_sum'] >= 100).astype(int)\n",
        "\n",
        "# High wind gust\n",
        "df['strong_wind'] = (df['wind_gust_max'] >= 20).astype(int)     # adjust threshold as needed\n",
        "df['very_strong_wind'] = (df['wind_gust_max'] >= 35).astype(int)\n",
        "\n",
        "# High soil moisture (landslide / soil hazard risk)\n",
        "df['high_soil_moisture'] = (df['soil_moisture_mean'] >= 0.6).astype(int)  # example threshold\n",
        "\n",
        "# -------------------------------\n",
        "# SEASONALITY (Philippine Monsoons)\n",
        "# -------------------------------\n",
        "df['month'] = df.index.month\n",
        "df['is_habagat'] = df['month'].isin([6, 7, 8, 9]).astype(int)\n",
        "df['is_amihan']  = df['month'].isin([11, 12, 1, 2]).astype(int)\n",
        "\n",
        "# -------------------------------\n",
        "# INTERACTION FEATURES\n",
        "# -------------------------------\n",
        "df['rain_soil_interaction'] = df['rain_sum'] * df['soil_moisture_mean']\n",
        "df['rain_wind_interaction'] = df['rain_sum'] * df['wind_gust_max']\n",
        "\n",
        "# -------------------------------\n",
        "# CLEANUP\n",
        "# -------------------------------\n",
        "# Drop NaNs created by lag/rolling features\n",
        "df = df.dropna()\n",
        "\n",
        "# Quick check\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "0-JUumCmlJ22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ncfLrWiisaDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5.5 TARGET VARIABLE DEFINITION"
      ],
      "metadata": {
        "id": "aALBee_Jsf44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 5.5 â€” TARGET VARIABLE DEFINITION (FIXED)\n",
        "# ==============================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------\n",
        "# 1ï¸âƒ£ FLOOD RISK\n",
        "# ------------------------------\n",
        "df[\"flood_risk\"] = np.where(\n",
        "    (df[\"rain_24h_sum\"] >= 50) |\n",
        "    ((df[\"rain_12h_sum\"] >= 30) &\n",
        "     (df[\"soil_moisture_mean\"] >= 0.35)) |\n",
        "    (df[\"soil_moisture_mean\"] >= 0.45),\n",
        "    1,\n",
        "    0\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 2ï¸âƒ£ HEAVY RAIN RISK\n",
        "# ------------------------------\n",
        "df[\"rain_risk\"] = np.where(\n",
        "    (df[\"rain_sum\"] >= 20) |\n",
        "    (df[\"rain_6h_sum\"] >= 40) |\n",
        "    (df[\"rain_12h_sum\"] >= 60),\n",
        "    1,\n",
        "    0\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 3ï¸âƒ£ STORM / WIND RISK\n",
        "# ------------------------------\n",
        "df[\"storm_risk\"] = np.where(\n",
        "    (df[\"wind_gust_max\"] >= 25) |\n",
        "    ((df[\"wind_gust_12h_max\"] >= 20) &\n",
        "     (df[\"rain_sum\"] >= 10)) |\n",
        "    (df[\"sea_level_pressure_mean\"].diff() <= -3),  # âœ… FIXED\n",
        "    1,\n",
        "    0\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 4ï¸âƒ£ LANDSLIDE / SOIL HAZARD RISK\n",
        "# ------------------------------\n",
        "df[\"landslide_risk\"] = np.where(\n",
        "    (df[\"soil_moisture_mean\"] >= 0.40) |\n",
        "    ((df[\"soil_24h_mean\"] >= 0.35) &\n",
        "     (df[\"rain_24h_sum\"] >= 40)),\n",
        "    1,\n",
        "    0\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# QUICK SANITY CHECK\n",
        "# ------------------------------\n",
        "print(\"Flood Risk:\\n\", df[\"flood_risk\"].value_counts())\n",
        "print(\"\\nRain Risk:\\n\", df[\"rain_risk\"].value_counts())\n",
        "print(\"\\nStorm Risk:\\n\", df[\"storm_risk\"].value_counts())\n",
        "print(\"\\nLandslide Risk:\\n\", df[\"landslide_risk\"].value_counts())\n"
      ],
      "metadata": {
        "id": "96NXcRFVr79p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6.1: Define Feature Groups"
      ],
      "metadata": {
        "id": "ccHlVvMK80-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ------------------------------\n",
        "# CONTINUOUS FEATURES (SCALE)\n",
        "# ------------------------------\n",
        "continuous_features = [\n",
        "    # Core meteorology\n",
        "    \"temperature_mean\",\n",
        "    \"relative_humidity_mean\",\n",
        "    \"sea_level_pressure_mean\",\n",
        "    \"wind_speed_max\",\n",
        "    \"wind_gust_max\", # Fixed: Renamed from \"wind_gusts_10m\"\n",
        "    \"visibility\",\n",
        "    \"cape\",\n",
        "    \"lifted_index\",\n",
        "    \"convective_inhibition\",\n",
        "\n",
        "    # Rain\n",
        "    \"rain_sum\",\n",
        "    \"precipitation_sum\",\n",
        "\n",
        "    # Soil\n",
        "    \"soil_moisture_mean\",\n",
        "\n",
        "    # Lag features\n",
        "    \"rain_lag1h\", \"rain_lag6h\", \"rain_lag24h\",\n",
        "    \"soil_lag1h\", \"soil_lag6h\", \"soil_lag24h\",\n",
        "\n",
        "    # Rolling rainfall\n",
        "    \"rain_6h_sum\", \"rain_12h_sum\", \"rain_24h_sum\", \"rain_24h_mean\",\n",
        "\n",
        "    # Interaction\n",
        "    \"rain_soil_interaction\"\n",
        "]\n",
        "\n",
        "# ------------------------------\n",
        "# BINARY / CATEGORICAL (NO SCALE)\n",
        "# ------------------------------\n",
        "binary_features = [\n",
        "    \"heavy_rain\",\n",
        "    \"very_heavy_rain\",\n",
        "    \"is_habagat\",\n",
        "    \"is_amihan\"\n",
        "]\n",
        "\n",
        "# Optional: cyclical month encoding (better than raw month)\n",
        "df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "\n",
        "cyclical_features = [\"month_sin\", \"month_cos\"]"
      ],
      "metadata": {
        "id": "PwrPYUP-83km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6.2: Applying Scaler Correctly"
      ],
      "metadata": {
        "id": "16sDJ2-Il70K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit scaler on continuous features only\n",
        "X_continuous_scaled = scaler.fit_transform(df[continuous_features])\n",
        "\n",
        "# Convert to DataFrame (important for alignment)\n",
        "X_continuous_scaled = pd.DataFrame(\n",
        "    X_continuous_scaled,\n",
        "    columns=continuous_features,\n",
        "    index=df.index\n",
        ")\n",
        "\n",
        "# Combine all features\n",
        "X = pd.concat(\n",
        "    [\n",
        "        X_continuous_scaled,\n",
        "        df[binary_features + cyclical_features]\n",
        "    ],\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "iM2igMcil8LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6.3 â€” Define Targets (Multi-Risk Ready)"
      ],
      "metadata": {
        "id": "obNTPD6emV1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets\n",
        "y_flood = df[\"flood_risk\"]\n",
        "y_rain = df[\"rain_risk\"]\n",
        "y_storm = df[\"storm_risk\"]\n",
        "y_landslide = df[\"landslide_risk\"]\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Flood target shape:\", y_flood.shape)\n"
      ],
      "metadata": {
        "id": "tddkEdO5mais"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6.5: Class Imbalance Handling"
      ],
      "metadata": {
        "id": "ppFfm4jwobvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 6.5 â€” CLASS IMBALANCE HANDLING\n",
        "# ===============================\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Target variable (example: flood)\n",
        "y = df['flood_risk']\n",
        "\n",
        "# Automatically compute balanced class weights\n",
        "classes = np.unique(y)\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y\n",
        ")\n",
        "\n",
        "# Convert to dictionary format\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "print(\"Computed class weights:\")\n",
        "print(class_weight_dict)\n"
      ],
      "metadata": {
        "id": "GOjw_FfpobRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Train/Test Split"
      ],
      "metadata": {
        "id": "2DWe-xft4X-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 7 â€” TRAINING MODELS WITH CLASS IMBALANCE HANDLING\n",
        "# ===============================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE  # for oversampling rare events\n",
        "\n",
        "risk_targets = ['flood_risk', 'rain_risk', 'storm_risk', 'landslide_risk']\n",
        "\n",
        "# Dictionary to store trained models\n",
        "models = {}\n",
        "\n",
        "# Loop through each risk target\n",
        "for target in risk_targets:\n",
        "    print(f\"\\nTraining model for: {target}\")\n",
        "\n",
        "    y = df[target]\n",
        "    # X is already the scaled features from Step 6.2 (cell iM2igMcil8LT).\n",
        "    # Do NOT redefine X here using df[feature_cols] as it would use unscaled data\n",
        "    # and potentially a different feature set than prepared in Step 6.2.\n",
        "\n",
        "    # Split into train/test (80-20)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # ----------------------------\n",
        "    # Handle class imbalance using SMOTE\n",
        "    # ----------------------------\n",
        "    # Check if y_train contains at least two classes before applying SMOTE\n",
        "    if len(y_train.value_counts()) < 2:\n",
        "        print(f\"Skipping SMOTE and training for {target}: Training data has only one class.\")\n",
        "        continue # Skip to the next target\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(f\"Before SMOTE: {y_train.value_counts().to_dict()}\")\n",
        "    print(f\"After SMOTE:  {y_train_res.value_counts().to_dict()}\")\n",
        "\n",
        "    # ----------------------------\n",
        "    # Train Random Forest\n",
        "    # ----------------------------\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        random_state=42,\n",
        "        class_weight='balanced',  # optional, already handled by SMOTE\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    clf.fit(X_train_res, y_train_res)\n",
        "\n",
        "    # Store the trained model in the dictionary\n",
        "    models[target] = clf\n",
        "\n",
        "    # ----------------------------\n",
        "    # Evaluate\n",
        "    # ----------------------------\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "id": "-HaqbOIg4Z-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Feature Importance"
      ],
      "metadata": {
        "id": "wLT2nR_u__8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 8 â€” FEATURE IMPORTANCE (Updated)\n",
        "# ===============================\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Dictionary of trained models. Use the 'models' dictionary from Step 7.\n",
        "# Ensure 'models' is available in the global scope after running Step 7.\n",
        "models_dict = models # Assuming 'models' dictionary is available from previous cell execution\n",
        "\n",
        "# Get the feature columns used for training (from the 'X' DataFrame)\n",
        "# This assumes X is still in scope and contains the features used for training.\n",
        "feature_cols_for_importance = X.columns.tolist()\n",
        "\n",
        "for risk_name, model in models_dict.items():\n",
        "    # Check if the model has feature_importances_ (e.g., RandomForest)\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        # Extract feature importance\n",
        "        importance = model.feature_importances_\n",
        "\n",
        "        # Create DataFrame\n",
        "        feat_imp_df = pd.DataFrame({\n",
        "            \"Feature\": feature_cols_for_importance,\n",
        "            \"Importance\": importance\n",
        "        }).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "        # Print top features\n",
        "        print(f\"\\n=== Feature Importance for {risk_name} ===\")\n",
        "        print(feat_imp_df.head(15))  # top 15\n",
        "\n",
        "        # Optional: Plot\n",
        "        plt.figure(figsize=(10,6))\n",
        "        sns.barplot(x=\"Importance\", y=\"Feature\", data=feat_imp_df.head(15), palette=\"viridis\", hue=\"Feature\", legend=False)\n",
        "        plt.title(f\"Top 15 Feature Importance â€” {risk_name}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"\\n=== Feature Importance for {risk_name} ===\")\n",
        "        print(f\"Model type {type(model).__name__} does not have feature_importances_ attribute.\")\n",
        "        print(\"Consider other methods for feature importance for this model type.\")"
      ],
      "metadata": {
        "id": "-2CaFp5T_YcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Season 2: Plugging-in the Real Time Data"
      ],
      "metadata": {
        "id": "veSPkdRo5Cfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Install libraries"
      ],
      "metadata": {
        "id": "LSogCpWbPXbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install\n",
        "\n",
        "!pip install openmeteo-requests\n",
        "!pip install requests-cache retry-requests numpy pandas"
      ],
      "metadata": {
        "id": "9dB03JtQ6HgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-4: Fetch Real Time Data, Handle NaN"
      ],
      "metadata": {
        "id": "jaqusF5AOuQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 2 + 2.5 â€” FETCH REAL-TIME HOURLY DATA & HANDLE NaNs\n",
        "# ===============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests_cache\n",
        "from retry_requests import retry\n",
        "import openmeteo_requests\n",
        "\n",
        "# -------------------------------\n",
        "# API Setup\n",
        "# -------------------------------\n",
        "cache_session = requests_cache.CachedSession(\n",
        "    '.cache', expire_after=3600\n",
        ")\n",
        "retry_session = retry(\n",
        "    cache_session, retries=5, backoff_factor=0.2\n",
        ")\n",
        "openmeteo = openmeteo_requests.Client(\n",
        "    session=retry_session\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# API Request\n",
        "# -------------------------------\n",
        "url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "params = {\n",
        "    \"latitude\": 14.5995,\n",
        "    \"longitude\": 120.9842,\n",
        "    \"hourly\": [\n",
        "        \"temperature_2m\",\n",
        "        \"relative_humidity_2m\",\n",
        "        \"dew_point_2m\",\n",
        "        \"pressure_msl\",\n",
        "        \"cloud_cover\",\n",
        "        \"wind_speed_10m\",\n",
        "        \"wind_gusts_10m\",\n",
        "        \"precipitation\",\n",
        "        \"rain\",\n",
        "        \"soil_moisture_0_to_1cm\",\n",
        "        \"soil_moisture_1_to_3cm\",\n",
        "        \"soil_moisture_3_to_9cm\",\n",
        "        \"soil_moisture_9_to_27cm\",\n",
        "        \"soil_moisture_27_to_81cm\",\n",
        "        \"soil_temperature_0cm\",\n",
        "        \"soil_temperature_6cm\",\n",
        "        \"soil_temperature_18cm\",\n",
        "        \"soil_temperature_54cm\"\n",
        "    ],\n",
        "    \"timezone\": \"Asia/Singapore\"\n",
        "}\n",
        "\n",
        "responses = openmeteo.weather_api(url, params=params)\n",
        "response = responses[0]\n",
        "\n",
        "# -------------------------------\n",
        "# Extract Hourly Data\n",
        "# -------------------------------\n",
        "hourly = response.Hourly()\n",
        "\n",
        "hourly_data = {\n",
        "    \"date\": pd.date_range(\n",
        "        start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
        "        end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
        "        freq=pd.Timedelta(seconds=hourly.Interval()),\n",
        "        inclusive=\"left\"\n",
        "    ),\n",
        "    \"temperature_2m\": hourly.Variables(0).ValuesAsNumpy(),\n",
        "    \"relative_humidity_2m\": hourly.Variables(1).ValuesAsNumpy(),\n",
        "    \"dew_point_2m\": hourly.Variables(2).ValuesAsNumpy(),\n",
        "    \"pressure_msl\": hourly.Variables(3).ValuesAsNumpy(),\n",
        "    \"cloud_cover\": hourly.Variables(4).ValuesAsNumpy(),\n",
        "    \"wind_speed_10m\": hourly.Variables(5).ValuesAsNumpy(),\n",
        "    \"wind_gusts_10m\": hourly.Variables(6).ValuesAsNumpy(),\n",
        "    \"precipitation\": hourly.Variables(7).ValuesAsNumpy(),\n",
        "    \"rain\": hourly.Variables(8).ValuesAsNumpy(),\n",
        "    \"soil_moisture_0_to_1cm\": hourly.Variables(9).ValuesAsNumpy(),\n",
        "    \"soil_moisture_1_to_3cm\": hourly.Variables(10).ValuesAsNumpy(),\n",
        "    \"soil_moisture_3_to_9cm\": hourly.Variables(11).ValuesAsNumpy(),\n",
        "    \"soil_moisture_9_to_27cm\": hourly.Variables(12).ValuesAsNumpy(),\n",
        "    \"soil_moisture_27_to_81cm\": hourly.Variables(13).ValuesAsNumpy(),\n",
        "    \"soil_temperature_0cm\": hourly.Variables(14).ValuesAsNumpy(),\n",
        "    \"soil_temperature_6cm\": hourly.Variables(15).ValuesAsNumpy(),\n",
        "    \"soil_temperature_18cm\": hourly.Variables(16).ValuesAsNumpy(),\n",
        "    \"soil_temperature_54cm\": hourly.Variables(17).ValuesAsNumpy()\n",
        "}\n",
        "\n",
        "hourly_df = pd.DataFrame(hourly_data)\n",
        "\n",
        "# -------------------------------\n",
        "# Timezone Conversion (Asia/Manila)\n",
        "# -------------------------------\n",
        "hourly_df[\"date\"] = (\n",
        "    pd.to_datetime(hourly_df[\"date\"], utc=True)\n",
        "    .dt.tz_convert(\"Asia/Manila\")\n",
        "    .dt.tz_localize(None)\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Rename Columns (Model-Compatible)\n",
        "# -------------------------------\n",
        "hourly_df.rename(columns={\n",
        "    \"temperature_2m\": \"temperature_mean\",\n",
        "    \"relative_humidity_2m\": \"relative_humidity_mean\",\n",
        "    \"pressure_msl\": \"sea_level_pressure_mean\",\n",
        "    \"soil_moisture_27_to_81cm\": \"soil_moisture_mean\",\n",
        "    \"wind_speed_10m\": \"wind_speed_max\",\n",
        "    \"wind_gusts_10m\": \"wind_gust_max\",\n",
        "    \"precipitation\": \"precipitation_sum\",\n",
        "    \"rain\": \"rain_sum\",\n",
        "    \"cloud_cover\": \"cloud_cover_total\",\n",
        "    \"dew_point_2m\": \"dew_point_mean\",\n",
        "    \"soil_moisture_0_to_1cm\": \"soil_moisture_top\",\n",
        "    \"soil_moisture_1_to_3cm\": \"soil_moisture_1_3cm\",\n",
        "    \"soil_moisture_3_to_9cm\": \"soil_moisture_3_9cm\",\n",
        "    \"soil_moisture_9_to_27cm\": \"soil_moisture_9_27cm\",\n",
        "    \"soil_temperature_0cm\": \"soil_temperature_top\",\n",
        "    \"soil_temperature_6cm\": \"soil_temperature_6cm\",\n",
        "    \"soil_temperature_18cm\": \"soil_temperature_18cm\",\n",
        "    \"soil_temperature_54cm\": \"soil_temperature_54cm\"\n",
        "}, inplace=True)\n",
        "\n",
        "# ===============================\n",
        "# STEP 2.5 â€” HANDLE NaN VALUES\n",
        "# ===============================\n",
        "\n",
        "# Strategy:\n",
        "# 1. Numeric â†’ interpolate (time-aware)\n",
        "# 2. Remaining NaNs â†’ forward fill\n",
        "# 3. Still NaN (edge cases) â†’ median fallback\n",
        "\n",
        "numeric_cols = hourly_df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Time interpolation\n",
        "hourly_df[numeric_cols] = hourly_df[numeric_cols].interpolate(\n",
        "    method=\"linear\", limit_direction=\"both\"\n",
        ")\n",
        "\n",
        "# Forward fill (short gaps)\n",
        "hourly_df[numeric_cols] = hourly_df[numeric_cols].ffill()\n",
        "\n",
        "# Median fallback (last resort safety)\n",
        "for col in numeric_cols:\n",
        "    hourly_df[col].fillna(hourly_df[col].median(), inplace=True)\n",
        "\n",
        "print(\"âœ… STEP 2 + 2.5 COMPLETE\")\n",
        "print(\"Remaining NaNs:\", hourly_df.isna().sum().sum())\n",
        "print(hourly_df.head())\n"
      ],
      "metadata": {
        "id": "XgZvU3j86ZJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Feature Engineering"
      ],
      "metadata": {
        "id": "yjpfP0cZ5eSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 5 â€” FEATURE ENGINEERING (REAL-TIME HOURLY)\n",
        "# ===============================\n",
        "\n",
        "df_feat = hourly_dataframe.copy()\n",
        "\n",
        "# ------------------------------\n",
        "# 0. Ensure datetime column exists\n",
        "# ------------------------------\n",
        "if \"date\" not in df_feat.columns:\n",
        "    if df_feat.index.name == \"date\":\n",
        "        df_feat = df_feat.reset_index()\n",
        "    else:\n",
        "        raise KeyError(\n",
        "            \"No 'date' column or datetime index found. \"\n",
        "            \"Real-time data must have a timestamp.\"\n",
        "        )\n",
        "\n",
        "# ------------------------------\n",
        "# 0. Safety check & fallback renaming\n",
        "# ------------------------------\n",
        "if \"rain_sum\" not in df_feat.columns:\n",
        "    if \"rain\" in df_feat.columns:\n",
        "        df_feat.rename(columns={\"rain\": \"rain_sum\"}, inplace=True)\n",
        "    else:\n",
        "        raise KeyError(\"Neither 'rain_sum' nor 'rain' found in dataframe\")\n",
        "\n",
        "if \"precipitation_sum\" not in df_feat.columns:\n",
        "    if \"precipitation\" in df_feat.columns:\n",
        "        df_feat.rename(columns={\"precipitation\": \"precipitation_sum\"}, inplace=True)\n",
        "\n",
        "# Soil moisture (deep layer)\n",
        "if \"soil_moisture_mean\" not in df_feat.columns:\n",
        "    if \"soil_moisture_27_to_81cm\" in df_feat.columns:\n",
        "        df_feat.rename(\n",
        "            columns={\"soil_moisture_27_to_81cm\": \"soil_moisture_mean\"},\n",
        "            inplace=True\n",
        "        )\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Ensure proper datetime index\n",
        "# ------------------------------\n",
        "df_feat = df_feat.sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Rain lag features (CRITICAL)\n",
        "# ------------------------------\n",
        "df_feat[\"rain_lag1h\"]  = df_feat[\"rain_sum\"].shift(1)\n",
        "df_feat[\"rain_lag6h\"]  = df_feat[\"rain_sum\"].shift(6)\n",
        "df_feat[\"rain_lag24h\"] = df_feat[\"rain_sum\"].shift(24)\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Soil moisture lag features (THIS FIXES YOUR ERROR)\n",
        "# ------------------------------\n",
        "df_feat[\"soil_lag1h\"]  = df_feat[\"soil_moisture_mean\"].shift(1)\n",
        "df_feat[\"soil_lag6h\"]  = df_feat[\"soil_moisture_mean\"].shift(6)\n",
        "df_feat[\"soil_lag24h\"] = df_feat[\"soil_moisture_mean\"].shift(24)\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Rolling rainfall accumulation\n",
        "# ------------------------------\n",
        "df_feat[\"rain_6h_sum\"]  = df_feat[\"rain_sum\"].rolling(6).sum()\n",
        "df_feat[\"rain_12h_sum\"] = df_feat[\"rain_sum\"].rolling(12).sum()\n",
        "df_feat[\"rain_24h_sum\"] = df_feat[\"rain_sum\"].rolling(24).sum()\n",
        "df_feat[\"rain_24h_mean\"] = df_feat[\"rain_sum\"].rolling(24).mean()\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Extreme rainfall flags\n",
        "# ------------------------------\n",
        "df_feat[\"heavy_rain\"] = (df_feat[\"rain_24h_sum\"] > 50).astype(int)\n",
        "df_feat[\"very_heavy_rain\"] = (df_feat[\"rain_24h_sum\"] > 100).astype(int)\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Time-based features\n",
        "# ------------------------------\n",
        "df_feat[\"month\"] = df_feat[\"date\"].dt.month\n",
        "\n",
        "# Amihan / Habagat (PH context)\n",
        "df_feat[\"is_amihan\"] = df_feat[\"month\"].isin([11,12,1,2,3]).astype(int)\n",
        "df_feat[\"is_habagat\"] = df_feat[\"month\"].isin([6,7,8,9]).astype(int)\n",
        "\n",
        "# ------------------------------\n",
        "# 7. Interaction features\n",
        "# ------------------------------\n",
        "df_feat[\"rain_soil_interaction\"] = (\n",
        "    df_feat[\"rain_24h_sum\"] * df_feat[\"soil_moisture_mean\"]\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 8. Handle NaNs from lagging/rolling\n",
        "# ------------------------------\n",
        "df_feat = df_feat.ffill().bfill()\n",
        "\n",
        "print(\"STEP 5 complete â€” Feature engineered real-time data ready\")\n",
        "print(df_feat.head())\n"
      ],
      "metadata": {
        "id": "6meoBWSJ5aT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "lmByIRIVBqPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 6: SCALE FEATURES & PREDICT RISKS PROBABILITY"
      ],
      "metadata": {
        "id": "qE4iWSFpSUaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 6 â€” SCALE FEATURES & PREDICT REAL-TIME RISKS (Refactored)\n",
        "# ===============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Feature Engineering Function\n",
        "# ------------------------------\n",
        "def engineer_features(df):\n",
        "    \"\"\"Feature engineering for both training and real-time prediction.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Ensure date is datetime\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "    else:\n",
        "        raise KeyError(\"Missing 'date' column in dataframe\")\n",
        "\n",
        "    # --- Time-based features ---\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['is_habagat'] = df['month'].isin([6,7,8,9]).astype(int)  # Jun-Sep\n",
        "    # Corrected: is_amihan to match historical processing [11,12,1,2]\n",
        "    df['is_amihan'] = df['month'].isin([11,12,1,2]).astype(int) # Nov-Feb\n",
        "    # Cyclical encoding\n",
        "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "\n",
        "    # --- Lag features ---\n",
        "    lag_hours = [1,6,24]\n",
        "    for lag in lag_hours:\n",
        "        df[f'rain_lag{lag}h'] = df['rain_sum'].shift(lag).fillna(0)\n",
        "        df[f'soil_lag{lag}h'] = df['soil_moisture_mean'].shift(lag).fillna(0)\n",
        "\n",
        "    # --- Rolling sums / means ---\n",
        "    df['rain_6h_sum'] = df['rain_sum'].rolling(6, min_periods=1).sum()\n",
        "    df['rain_12h_sum'] = df['rain_sum'].rolling(12, min_periods=1).sum()\n",
        "    df['rain_24h_sum'] = df['rain_sum'].rolling(24, min_periods=1).sum()\n",
        "    df['rain_24h_mean'] = df['rain_sum'].rolling(24, min_periods=1).mean()\n",
        "\n",
        "    # --- Threshold flags ---\n",
        "    df['heavy_rain'] = (df['rain_sum'] >= 7.5).astype(int)\n",
        "    df['very_heavy_rain'] = (df['rain_sum'] >= 15.0).astype(int)\n",
        "\n",
        "    # --- Interaction terms ---\n",
        "    df['rain_soil_interaction'] = df['rain_sum'] * df['soil_moisture_mean']\n",
        "\n",
        "    # --- Placeholder columns for missing features in real-time API ---\n",
        "    missing_features = ['visibility', 'cape', 'lifted_index', 'convective_inhibition']\n",
        "    for feature in missing_features:\n",
        "        if feature not in df.columns:\n",
        "            df[feature] = 0.0\n",
        "\n",
        "    # --- Fill any remaining NaNs ---\n",
        "    df.ffill(inplace=True)\n",
        "    df.bfill(inplace=True)\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    # Set 'date' as index to match training data's X structure\n",
        "    df = df.set_index('date').sort_index()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Apply feature engineering\n",
        "# ------------------------------\n",
        "# Corrected: Pass hourly_df (real-time data) instead of df (historical data)\n",
        "df_real_time = engineer_features(hourly_df)\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Scaling continuous features\n",
        "# ------------------------------\n",
        "X_continuous_real_time = df_real_time[continuous_features]  # from training\n",
        "X_continuous_scaled = scaler.transform(X_continuous_real_time)\n",
        "X_continuous_scaled_df = pd.DataFrame(\n",
        "    X_continuous_scaled,\n",
        "    columns=continuous_features,\n",
        "    index=df_real_time.index\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Combine all features for prediction\n",
        "# ------------------------------\n",
        "X_for_prediction = pd.concat(\n",
        "    [X_continuous_scaled_df, df_real_time[binary_features + cyclical_features]],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Ensure feature order matches training\n",
        "# ------------------------------\n",
        "if list(X_for_prediction.columns) != list(X_train.columns):\n",
        "    raise ValueError(\"Feature order mismatch! Columns must match training data.\")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Predict probabilities & classes for all risks\n",
        "# ------------------------------\n",
        "risk_targets = ['flood_risk', 'rain_risk', 'storm_risk', 'landslide_risk']\n",
        "\n",
        "for risk_name in risk_targets:\n",
        "    model = models[risk_name]\n",
        "    df_real_time[f'{risk_name}_prob'] = model.predict_proba(X_for_prediction)[:,1]\n",
        "    df_real_time[f'{risk_name}_pred'] = model.predict(X_for_prediction)\n",
        "\n",
        "# ------------------------------\n",
        "# 7. Preview\n",
        "# ------------------------------\n",
        "print(\"Real-time predictions added:\")\n",
        "print(df_real_time[[f'{r}_pred' for r in risk_targets] + [f'{r}_prob' for r in risk_targets]].head())\n"
      ],
      "metadata": {
        "id": "ZcGUEfE6SUyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SEASON 3 â€” DEEP LEARNING (RECOMMENDER)"
      ],
      "metadata": {
        "id": "YjJ1JGBkyFI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 1 PREPARE SEQUENTIAL DATA FOR DL"
      ],
      "metadata": {
        "id": "-UMWsj8fStw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 1 PREPARE SEQUENTIAL DATA FOR DL\n",
        "# ===============================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Select features for DL\n",
        "# ------------------------------\n",
        "dl_features = [\n",
        "    \"flood_risk_prob\",\n",
        "    \"rain_risk_prob\",\n",
        "    \"storm_risk_prob\",\n",
        "    \"landslide_risk_prob\"\n",
        "]\n",
        "\n",
        "df_dl = df_real_time[dl_features].copy()\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Define sequence length\n",
        "# ------------------------------\n",
        "SEQUENCE_LENGTH = 24  # last 24 hours\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Create sequences\n",
        "# ------------------------------\n",
        "X_sequences = []\n",
        "y_targets = []\n",
        "\n",
        "for i in range(len(df_dl) - SEQUENCE_LENGTH):\n",
        "    # Input sequence (past 24 hours)\n",
        "    X_seq = df_dl.iloc[i:i + SEQUENCE_LENGTH].values\n",
        "\n",
        "    # Target (next hour storm risk probability)\n",
        "    y_target = df_dl.iloc[i + SEQUENCE_LENGTH][\"storm_risk_prob\"]\n",
        "\n",
        "    X_sequences.append(X_seq)\n",
        "    y_targets.append(y_target)\n",
        "\n",
        "# Convert to NumPy arrays (DL-friendly)\n",
        "X_sequences = np.array(X_sequences)\n",
        "y_targets = np.array(y_targets)\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Shape check\n",
        "# ------------------------------\n",
        "print(\"DL Input shape (X):\", X_sequences.shape)\n",
        "print(\"DL Target shape (y):\", y_targets.shape)\n",
        "\n",
        "print(\"\\nSample sequence (first one):\")\n",
        "print(X_sequences[0])\n",
        "\n",
        "print(\"\\nCorresponding target:\")\n",
        "print(y_targets[0])\n"
      ],
      "metadata": {
        "id": "rcxPQDSrSHFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2 â€” BUILD & TRAIN LSTM MODEL"
      ],
      "metadata": {
        "id": "zTv3vTGXSmw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 2 â€” BUILD & TRAIN LSTM MODEL\n",
        "# ===============================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 1. Define model\n",
        "lstm_model = Sequential([\n",
        "    # Corrected input_shape to use X_sequences dimensions\n",
        "    LSTM(32, input_shape=(X_sequences.shape[1], X_sequences.shape[2]), return_sequences=False),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Predict next-hour probability (regression)\n",
        "])\n",
        "\n",
        "lstm_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "lstm_model.summary()\n",
        "\n",
        "# 2. Early stopping to prevent overfitting\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='loss',  # since small dataset, monitor training loss\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 3. Train\n",
        "history = lstm_model.fit(\n",
        "    X_sequences, y_targets, # Corrected to use the prepared sequential data and targets\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "7Zc04ycfSnIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 3 â€” RULE-BASED RECOMMENDATIONS"
      ],
      "metadata": {
        "id": "o_qpZB0eTcU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 3 â€” RULE-BASED RECOMMENDATIONS\n",
        "# ===============================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define thresholds and messages\n",
        "def risk_alert(prob):\n",
        "    \"\"\"Convert probability into human-readable alert.\"\"\"\n",
        "    if prob < 0.1:\n",
        "        return \"Low Risk â€” No Action\"\n",
        "    elif prob < 0.3:\n",
        "        return \"Moderate Risk â€” Stay Alert\"\n",
        "    elif prob < 0.5:\n",
        "        return \"High Risk â€” Prepare Precautions\"\n",
        "    else:\n",
        "        return \"Severe Risk â€” Take Immediate Action\"\n",
        "\n",
        "# 2. Apply for each risk\n",
        "risk_probs = ['flood_risk_prob', 'rain_risk_prob', 'storm_risk_prob', 'landslide_risk_prob']\n",
        "for risk in risk_probs:\n",
        "    alert_col = risk.replace(\"_prob\", \"_alert\")\n",
        "    df_real_time[alert_col] = df_real_time[risk].apply(risk_alert)\n",
        "\n",
        "# 3. Optional: Combined summary alert (highest severity among all risks)\n",
        "def overall_alert(row):\n",
        "    severity_order = [\"Low Risk â€” No Action\", \"Moderate Risk â€” Stay Alert\",\n",
        "                      \"High Risk â€” Prepare Precautions\", \"Severe Risk â€” Take Immediate Action\"]\n",
        "    # Find the highest severity\n",
        "    probs = [row[r.replace(\"_prob\", \"_alert\")] for r in risk_probs]\n",
        "    highest_idx = max([severity_order.index(p) for p in probs])\n",
        "    return severity_order[highest_idx]\n",
        "\n",
        "df_real_time['overall_alert'] = df_real_time.apply(overall_alert, axis=1)\n",
        "\n",
        "# 4. Preview\n",
        "alert_cols = [r.replace(\"_prob\", \"_alert\") for r in risk_probs] + ['overall_alert']\n",
        "print(\"Rule-based recommendations added:\")\n",
        "print(df_real_time[alert_cols].head(10))\n"
      ],
      "metadata": {
        "id": "Hb8RRJW6Tcu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C4jiJoQZVy5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 4 â€” VISUALIZE REAL-TIME RISKS & ALERT LEVELS\n",
        "# ===============================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import numpy as np\n",
        "\n",
        "# Copy of dataframe to avoid modifying original\n",
        "df_viz = df_real_time.copy()\n",
        "\n",
        "# Convert alert levels to numeric codes for visualization\n",
        "alert_mapping = {\n",
        "    \"Low Risk â€” No Action\": 0,\n",
        "    \"Moderate Risk â€” Stay Alert\": 1,\n",
        "    \"High Risk â€” Prepare Precautions\": 2,\n",
        "    \"Severe Risk â€” Take Immediate Action\": 3\n",
        "}\n",
        "\n",
        "for risk in ['flood_risk', 'rain_risk', 'storm_risk', 'landslide_risk']:\n",
        "    df_viz[f'{risk}_alert_code'] = df_viz[f'{risk}_alert'].map(alert_mapping)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "colors = {\n",
        "    'flood_risk': 'blue',\n",
        "    'rain_risk': 'green',\n",
        "    'storm_risk': 'orange',\n",
        "    'landslide_risk': 'purple'\n",
        "}\n",
        "\n",
        "alert_colors = {\n",
        "    0: 'green',\n",
        "    1: 'yellow',\n",
        "    2: 'orange',\n",
        "    3: 'red'\n",
        "}\n",
        "\n",
        "for risk in ['flood_risk', 'rain_risk', 'storm_risk', 'landslide_risk']:\n",
        "    # Plot probability line\n",
        "    plt.plot(df_viz.index, df_viz[f'{risk}_prob'], label=f'{risk} probability', color=colors[risk])\n",
        "\n",
        "    # Overlay alert levels as dots\n",
        "    plt.scatter(\n",
        "        df_viz.index,\n",
        "        df_viz[f'{risk}_alert_code'] * 0.25,  # scale to fit below probability (adjust if needed)\n",
        "        color=[alert_colors[x] for x in df_viz[f'{risk}_alert_code']],\n",
        "        label=f'{risk} alert',\n",
        "        marker='o',\n",
        "        s=30,\n",
        "        alpha=0.6\n",
        "    )\n",
        "\n",
        "plt.title(\"Real-Time Risk Probabilities and Rule-Based Alerts\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.ylim(0, 1.05)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Improve x-axis date formatting\n",
        "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Legend\n",
        "plt.legend(loc='upper left', fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CodCV6zHVzRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the risk probabilities and corresponding text alerts\n",
        "\n",
        "# Select the probability and alert columns\n",
        "output_cols = [\n",
        "    'flood_risk_prob', 'rain_risk_prob', 'storm_risk_prob', 'landslide_risk_prob',\n",
        "    'flood_risk_alert', 'rain_risk_alert', 'storm_risk_alert', 'landslide_risk_alert',\n",
        "    'overall_alert'\n",
        "]\n",
        "\n",
        "# Display the head of the DataFrame with these columns\n",
        "print(\"Current Real-time Risk Probabilities and Alerts:\")\n",
        "print(df_real_time[output_cols].head())\n",
        "\n",
        "# You can also display a specific time range, for example, the last few hours:\n",
        "print(\"\\nLast 5 hours of Real-time Risk Probabilities and Alerts:\")\n",
        "print(df_real_time[output_cols].tail())\n"
      ],
      "metadata": {
        "id": "HMu83NkmXzeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9o6jPNbXWy08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Map alerts to numeric values\n",
        "severity_map = {\n",
        "    \"Low Risk â€” No Action\": 0,\n",
        "    \"Moderate Risk â€” Stay Alert\": 1,\n",
        "    \"High Risk â€” Prepare Precautions\": 2,\n",
        "    \"Severe Risk â€” Take Immediate Action\": 3\n",
        "}\n",
        "\n",
        "# Apply mapping\n",
        "alert_cols = ['flood_risk_alert', 'rain_risk_alert', 'storm_risk_alert', 'landslide_risk_alert']\n",
        "df_alert_numeric = df_real_time[alert_cols].replace(severity_map)\n",
        "\n",
        "# Colors for each severity\n",
        "colors = ['green', 'yellow', 'orange', 'red']\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "\n",
        "# Plot each risk's alert over time\n",
        "for col in alert_cols:\n",
        "    plt.scatter(df_alert_numeric.index, df_alert_numeric[col],\n",
        "                c=df_alert_numeric[col].map(lambda x: colors[x]),\n",
        "                s=80, label=col, edgecolor='black')\n",
        "\n",
        "plt.title('Rule-Based Risk Alerts (Human-Friendly)')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Alert Level')\n",
        "plt.yticks([0,1,2,3], [\"Low\", \"Moderate\", \"High\", \"Severe\"])\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RbSv6s-uWzJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}